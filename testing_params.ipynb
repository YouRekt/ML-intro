{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for generating stuff to be used in the report\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='spectrograms/train', transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_mean = torch.stack([img.mean(1).mean(1) for img, _ in train_dataset]).mean(0)\n",
    "train_std = torch.stack([img.std(1).std(1) for img, _ in train_dataset]).mean(0)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\"spectrograms/train\", transform=data_transforms)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [0.8,0.2])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\"spectrograms/test\", transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\"spectrograms/test\", transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=26912, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 29 * 29, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "epochs = 2\n",
    "params = [\n",
    "    {\"lr\": 0.001, \"momentum\": 0.9, \"title\": \"lr=0.001, momentum=0.9\"},\n",
    "    {\"lr\": 0.01, \"momentum\": 0.9, \"title\": \"lr=0.01, momentum=0.9\"},\n",
    "    {\"lr\": 0.001, \"momentum\": 0.5, \"title\": \"lr=0.001, momentum=0.5\"},\n",
    "    {\"lr\": 0.01, \"momentum\": 0.5, \"title\": \"lr=0.01, momentum=0.5\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwaluzenicz-ignacy\u001b[0m (\u001b[33mIntro-ML\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ignacy-waluzenicz/code/iml/ML-intro/wandb/run-20250127_200044-rh47dzhv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/rh47dzhv' target=\"_blank\">skilled-firebrand-17</a></strong> to <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/rh47dzhv' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition/runs/rh47dzhv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.694\n",
      "[1,   400] loss: 0.692\n",
      "[1,   600] loss: 0.688\n",
      "[1,   800] loss: 0.684\n",
      "[1,  1000] loss: 0.650\n",
      "[1,  1200] loss: 0.568\n",
      "[1,  1400] loss: 0.521\n",
      "[1,  1600] loss: 0.451\n",
      "[1,  1800] loss: 0.422\n",
      "[1,  2000] loss: 0.357\n",
      "[1,  2200] loss: 0.349\n",
      "[1,  2400] loss: 0.327\n",
      "[1,  2600] loss: 0.347\n",
      "[1,  2800] loss: 0.279\n",
      "[1,  3000] loss: 0.264\n",
      "[1,  3200] loss: 0.269\n",
      "[1,  3400] loss: 0.246\n",
      "[1,  3600] loss: 0.257\n",
      "[1,  3800] loss: 0.205\n",
      "[1,  4000] loss: 0.240\n",
      "[1,  4200] loss: 0.177\n",
      "[1,  4400] loss: 0.191\n",
      "[1,  4600] loss: 0.147\n",
      "[1,  4800] loss: 0.159\n",
      "[1,  5000] loss: 0.168\n",
      "[1,  5200] loss: 0.136\n",
      "[1,  5400] loss: 0.129\n",
      "[1,  5600] loss: 0.146\n",
      "[1,  5800] loss: 0.135\n",
      "[1,  6000] loss: 0.110\n",
      "[1,  6200] loss: 0.116\n",
      "[1,  6400] loss: 0.117\n",
      "[1,  6600] loss: 0.161\n",
      "[1,  6800] loss: 0.102\n",
      "[1,  7000] loss: 0.126\n",
      "[1,  7200] loss: 0.136\n",
      "[1,  7400] loss: 0.100\n",
      "[1,  7600] loss: 0.110\n",
      "[1,  7800] loss: 0.117\n",
      "[1,  8000] loss: 0.061\n",
      "[1,  8200] loss: 0.110\n",
      "Finished Training\n",
      "[2,   200] loss: 0.058\n",
      "[2,   400] loss: 0.106\n",
      "[2,   600] loss: 0.070\n",
      "[2,   800] loss: 0.072\n",
      "[2,  1000] loss: 0.070\n",
      "[2,  1200] loss: 0.096\n",
      "[2,  1400] loss: 0.067\n",
      "[2,  1600] loss: 0.081\n",
      "[2,  1800] loss: 0.071\n",
      "[2,  2000] loss: 0.084\n",
      "[2,  2200] loss: 0.079\n",
      "[2,  2400] loss: 0.046\n",
      "[2,  2600] loss: 0.066\n",
      "[2,  2800] loss: 0.058\n",
      "[2,  3000] loss: 0.069\n",
      "[2,  3200] loss: 0.063\n",
      "[2,  3400] loss: 0.061\n",
      "[2,  3600] loss: 0.064\n",
      "[2,  3800] loss: 0.065\n",
      "[2,  4000] loss: 0.065\n",
      "[2,  4200] loss: 0.039\n",
      "[2,  4400] loss: 0.059\n",
      "[2,  4600] loss: 0.046\n",
      "[2,  4800] loss: 0.044\n",
      "[2,  5000] loss: 0.050\n",
      "[2,  5200] loss: 0.039\n",
      "[2,  5400] loss: 0.075\n",
      "[2,  5600] loss: 0.066\n",
      "[2,  5800] loss: 0.052\n",
      "[2,  6000] loss: 0.073\n",
      "[2,  6200] loss: 0.080\n",
      "[2,  6400] loss: 0.041\n",
      "[2,  6600] loss: 0.074\n",
      "[2,  6800] loss: 0.060\n",
      "[2,  7000] loss: 0.060\n",
      "[2,  7200] loss: 0.046\n",
      "[2,  7400] loss: 0.063\n",
      "[2,  7600] loss: 0.036\n",
      "[2,  7800] loss: 0.065\n",
      "[2,  8000] loss: 0.056\n",
      "[2,  8200] loss: 0.036\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train acc</td><td>▁█</td></tr><tr><td>train loss</td><td>█▁</td></tr><tr><td>validation acc</td><td>▁█</td></tr><tr><td>validation loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train acc</td><td>0.9206</td></tr><tr><td>train loss</td><td>0.1672</td></tr><tr><td>validation acc</td><td>0.97833</td></tr><tr><td>validation loss</td><td>0.06375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-firebrand-17</strong> at: <a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/rh47dzhv' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition/runs/rh47dzhv</a><br/> View project at: <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250127_200044-rh47dzhv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ignacy-waluzenicz/code/iml/ML-intro/wandb/run-20250127_201139-60i7qv9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/60i7qv9t' target=\"_blank\">confused-oath-18</a></strong> to <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/60i7qv9t' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition/runs/60i7qv9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 95.792\n",
      "[1,   400] loss: 0.693\n",
      "[1,   600] loss: 0.695\n",
      "[1,   800] loss: 0.699\n",
      "[1,  1000] loss: 0.698\n",
      "[1,  1200] loss: 0.694\n",
      "[1,  1400] loss: 0.695\n",
      "[1,  1600] loss: 0.692\n",
      "[1,  1800] loss: 0.694\n",
      "[1,  2000] loss: 0.691\n",
      "[1,  2200] loss: 0.698\n",
      "[1,  2400] loss: 0.697\n",
      "[1,  2600] loss: 0.699\n",
      "[1,  2800] loss: 0.697\n",
      "[1,  3000] loss: 0.694\n",
      "[1,  3200] loss: 0.698\n",
      "[1,  3400] loss: 0.693\n",
      "[1,  3600] loss: 0.695\n",
      "[1,  3800] loss: 0.695\n",
      "[1,  4000] loss: 0.695\n",
      "[1,  4200] loss: 0.692\n",
      "[1,  4400] loss: 0.694\n",
      "[1,  4600] loss: 0.697\n",
      "[1,  4800] loss: 0.697\n",
      "[1,  5000] loss: 0.692\n",
      "[1,  5200] loss: 0.697\n",
      "[1,  5400] loss: 0.694\n",
      "[1,  5600] loss: 0.696\n",
      "[1,  5800] loss: 0.694\n",
      "[1,  6000] loss: 0.699\n",
      "[1,  6200] loss: 0.694\n",
      "[1,  6400] loss: 0.691\n",
      "[1,  6600] loss: 0.693\n",
      "[1,  6800] loss: 0.694\n",
      "[1,  7000] loss: 0.693\n",
      "[1,  7200] loss: 0.694\n",
      "[1,  7400] loss: 0.694\n",
      "[1,  7600] loss: 0.696\n",
      "[1,  7800] loss: 0.695\n",
      "[1,  8000] loss: 0.696\n",
      "[1,  8200] loss: 0.694\n",
      "Finished Training\n",
      "[2,   200] loss: 0.693\n",
      "[2,   400] loss: 0.694\n",
      "[2,   600] loss: 0.693\n",
      "[2,   800] loss: 0.698\n",
      "[2,  1000] loss: 0.698\n",
      "[2,  1200] loss: 0.698\n",
      "[2,  1400] loss: 0.696\n",
      "[2,  1600] loss: 0.697\n",
      "[2,  1800] loss: 0.695\n",
      "[2,  2000] loss: 0.694\n",
      "[2,  2200] loss: 0.692\n",
      "[2,  2400] loss: 0.693\n",
      "[2,  2600] loss: 0.696\n",
      "[2,  2800] loss: 0.694\n",
      "[2,  3000] loss: 0.696\n",
      "[2,  3200] loss: 0.693\n",
      "[2,  3400] loss: 0.696\n",
      "[2,  3600] loss: 0.692\n",
      "[2,  3800] loss: 0.694\n",
      "[2,  4000] loss: 0.692\n",
      "[2,  4200] loss: 0.695\n",
      "[2,  4400] loss: 0.694\n",
      "[2,  4600] loss: 0.686\n",
      "[2,  4800] loss: 0.697\n",
      "[2,  5000] loss: 0.694\n",
      "[2,  5200] loss: 0.690\n",
      "[2,  5400] loss: 0.702\n",
      "[2,  5600] loss: 0.696\n",
      "[2,  5800] loss: 0.697\n",
      "[2,  6000] loss: 0.694\n",
      "[2,  6200] loss: 0.696\n",
      "[2,  6400] loss: 0.696\n",
      "[2,  6600] loss: 0.697\n",
      "[2,  6800] loss: 0.692\n",
      "[2,  7000] loss: 0.693\n",
      "[2,  7200] loss: 0.691\n",
      "[2,  7400] loss: 0.693\n",
      "[2,  7600] loss: 0.696\n",
      "[2,  7800] loss: 0.695\n",
      "[2,  8000] loss: 0.696\n",
      "[2,  8200] loss: 0.696\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train acc</td><td>▁█</td></tr><tr><td>train loss</td><td>█▁</td></tr><tr><td>validation acc</td><td>█▁</td></tr><tr><td>validation loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train acc</td><td>0.51558</td></tr><tr><td>train loss</td><td>1.8335</td></tr><tr><td>validation acc</td><td>0.46533</td></tr><tr><td>validation loss</td><td>0.69379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-oath-18</strong> at: <a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/60i7qv9t' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition/runs/60i7qv9t</a><br/> View project at: <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250127_201139-60i7qv9t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ignacy-waluzenicz/code/iml/ML-intro/wandb/run-20250127_202350-0hdog31x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/0hdog31x' target=\"_blank\">ethereal-sound-19</a></strong> to <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Intro-ML/Voice-Recognition' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Intro-ML/Voice-Recognition/runs/0hdog31x' target=\"_blank\">https://wandb.ai/Intro-ML/Voice-Recognition/runs/0hdog31x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.693\n",
      "[1,   400] loss: 0.693\n",
      "[1,   600] loss: 0.693\n",
      "[1,   800] loss: 0.691\n",
      "[1,  1000] loss: 0.691\n",
      "[1,  1200] loss: 0.692\n",
      "[1,  1400] loss: 0.692\n",
      "[1,  1600] loss: 0.691\n",
      "[1,  1800] loss: 0.689\n",
      "[1,  2000] loss: 0.691\n",
      "[1,  2200] loss: 0.694\n",
      "[1,  2400] loss: 0.691\n",
      "[1,  2600] loss: 0.691\n",
      "[1,  2800] loss: 0.694\n",
      "[1,  3000] loss: 0.693\n",
      "[1,  3200] loss: 0.691\n",
      "[1,  3400] loss: 0.692\n",
      "[1,  3600] loss: 0.688\n",
      "[1,  3800] loss: 0.689\n",
      "[1,  4000] loss: 0.691\n",
      "[1,  4200] loss: 0.693\n",
      "[1,  4400] loss: 0.689\n",
      "[1,  4600] loss: 0.697\n",
      "[1,  4800] loss: 0.691\n",
      "[1,  5000] loss: 0.693\n",
      "[1,  5200] loss: 0.693\n",
      "[1,  5400] loss: 0.691\n",
      "[1,  5600] loss: 0.691\n",
      "[1,  5800] loss: 0.695\n",
      "[1,  6000] loss: 0.693\n",
      "[1,  6200] loss: 0.692\n",
      "[1,  6400] loss: 0.691\n",
      "[1,  6600] loss: 0.692\n",
      "[1,  6800] loss: 0.693\n",
      "[1,  7000] loss: 0.692\n",
      "[1,  7200] loss: 0.694\n",
      "[1,  7400] loss: 0.692\n",
      "[1,  7600] loss: 0.692\n",
      "[1,  7800] loss: 0.693\n",
      "[1,  8000] loss: 0.691\n",
      "[1,  8200] loss: 0.692\n",
      "Finished Training\n",
      "[2,   200] loss: 0.693\n",
      "[2,   400] loss: 0.691\n",
      "[2,   600] loss: 0.692\n",
      "[2,   800] loss: 0.693\n",
      "[2,  1000] loss: 0.690\n",
      "[2,  1200] loss: 0.693\n",
      "[2,  1400] loss: 0.693\n",
      "[2,  1600] loss: 0.692\n",
      "[2,  1800] loss: 0.693\n",
      "[2,  2000] loss: 0.692\n",
      "[2,  2200] loss: 0.692\n",
      "[2,  2400] loss: 0.690\n",
      "[2,  2600] loss: 0.693\n",
      "[2,  2800] loss: 0.690\n",
      "[2,  3000] loss: 0.690\n",
      "[2,  3200] loss: 0.689\n",
      "[2,  3400] loss: 0.691\n",
      "[2,  3600] loss: 0.691\n",
      "[2,  3800] loss: 0.692\n",
      "[2,  4000] loss: 0.693\n",
      "[2,  4200] loss: 0.692\n",
      "[2,  4400] loss: 0.692\n",
      "[2,  4600] loss: 0.691\n",
      "[2,  4800] loss: 0.694\n",
      "[2,  5000] loss: 0.694\n",
      "[2,  5200] loss: 0.692\n",
      "[2,  5400] loss: 0.693\n",
      "[2,  5600] loss: 0.692\n",
      "[2,  5800] loss: 0.692\n",
      "[2,  6000] loss: 0.693\n",
      "[2,  6200] loss: 0.690\n",
      "[2,  6400] loss: 0.694\n",
      "[2,  6600] loss: 0.693\n",
      "[2,  6800] loss: 0.692\n",
      "[2,  7000] loss: 0.693\n",
      "[2,  7200] loss: 0.689\n",
      "[2,  7400] loss: 0.692\n",
      "[2,  7600] loss: 0.692\n",
      "[2,  7800] loss: 0.692\n",
      "[2,  8000] loss: 0.691\n",
      "[2,  8200] loss: 0.690\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     46\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 47\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(images)\n\u001b[1;32m     48\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mappend(current_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/modules/pooling.py:213\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmax_pool2d(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation,\n\u001b[1;32m    219\u001b[0m         ceil_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[1;32m    220\u001b[0m         return_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_indices,\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/_jit_internal.py:624\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/torch/nn/functional.py:830\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28minput\u001b[39m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "for params_set in params:\n",
    "    wandb.init(project=\"Voice-Recognition\", group=\"model comps\", reinit=True)\n",
    "    wandb.run.name = params_set[\"title\"]\n",
    "    wandb.run.save()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=params_set[\"lr\"], momentum=params_set[\"momentum\"])\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    training_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            training_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 200 == 199:    # print every 200 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "                running_loss = 0.0\n",
    "        wandb.log({f\"train loss\": np.mean(training_loss), \"train acc\": correct_train / total_train})\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss = []\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in validloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                current_loss = criterion(outputs, labels)\n",
    "                loss.append(current_loss.item())\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "            wandb.log({\"validation loss\": np.mean(loss), \"validation acc\": correct / total})\n",
    "        print('Finished Training')\n",
    "    wandb.run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be000326c53d44bab4621a64f6855830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:451\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:393\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2149\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quiet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2142\u001b[0m     deprecate\u001b[38;5;241m.\u001b[39mdeprecate(\n\u001b[1;32m   2143\u001b[0m         field_name\u001b[38;5;241m=\u001b[39mdeprecate\u001b[38;5;241m.\u001b[39mDeprecated\u001b[38;5;241m.\u001b[39mrun__finish_quiet,\n\u001b[1;32m   2144\u001b[0m         warning_message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         ),\n\u001b[1;32m   2148\u001b[0m     )\n\u001b[0;32m-> 2149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(exit_code)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2179\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atexit_cleanup(exit_code\u001b[38;5;241m=\u001b[39mexit_code)\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# Run hooks that should happen after the last messages to the\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;66;03m# internal service, like detaching the logger.\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2432\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2429\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39mresume_fname)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_finish()\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mwandb_agent\u001b[38;5;241m.\u001b[39m_is_running():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2681\u001b[0m, in \u001b[0;36mRun._on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2674\u001b[0m exit_handle\u001b[38;5;241m.\u001b[39madd_probe(on_probe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_probe_exit)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mprogress_printer(\n\u001b[1;32m   2677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer,\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings,\n\u001b[1;32m   2679\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress_printer:\n\u001b[1;32m   2680\u001b[0m     \u001b[38;5;66;03m# Wait for the run to complete.\u001b[39;00m\n\u001b[0;32m-> 2681\u001b[0m     _ \u001b[38;5;241m=\u001b[39m exit_handle\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m   2682\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   2683\u001b[0m         on_progress\u001b[38;5;241m=\u001b[39mfunctools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2684\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_progress_exit,\n\u001b[1;32m   2685\u001b[0m             progress_printer,\n\u001b[1;32m   2686\u001b[0m         ),\n\u001b[1;32m   2687\u001b[0m     )\n\u001b[1;32m   2689\u001b[0m \u001b[38;5;66;03m# Print some final statistics.\u001b[39;00m\n\u001b[1;32m   2690\u001b[0m poll_exit_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_poll_exit()\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:279\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 279\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot\u001b[38;5;241m.\u001b[39m_get_and_clear(timeout\u001b[38;5;241m=\u001b[39mwait_timeout)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    125\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout\u001b[38;5;241m=\u001b[39mtimeout):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    128\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:122\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/iml/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
